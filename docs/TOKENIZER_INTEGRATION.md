# ğŸ”¤ åˆ†è¯å™¨åŠŸèƒ½å®Œå…¨é›†æˆè¯´æ˜

## ğŸ“‹ æ¦‚è¿°

New API v1.6.0 ä¸ä»…æ·»åŠ äº† Hugging Face TEI é‡æ’åºåŠŸèƒ½ï¼Œæ›´é‡è¦çš„æ˜¯**åˆ†è¯å™¨åŠŸèƒ½å·²å®Œå…¨é›†æˆ**åˆ°ç³»ç»Ÿä¸­ã€‚è¿™æ„å‘³ç€æ‚¨æ— éœ€ä¾èµ–å¤–éƒ¨åˆ†è¯å™¨æœåŠ¡ï¼Œæ‰€æœ‰æ–‡æœ¬å¤„ç†éƒ½åœ¨å†…éƒ¨å®Œæˆã€‚

## ğŸ¯ å®Œå…¨é›†æˆçš„å«ä¹‰

### ğŸ”¥ å†…ç½®åˆ†è¯å™¨å¤„ç†
- **æ— å¤–éƒ¨ä¾èµ–** - ä¸éœ€è¦é¢å¤–çš„åˆ†è¯å™¨æœåŠ¡æˆ– API
- **ç«¯åˆ°ç«¯å¤„ç†** - ä»åŸå§‹æ–‡æœ¬åˆ°é‡æ’åºç»“æœçš„å®Œæ•´æµç¨‹
- **ç»Ÿä¸€ç®¡ç†** - åˆ†è¯å™¨ä¸é‡æ’åºæ¨¡å‹ç»Ÿä¸€ç®¡ç†å’Œéƒ¨ç½²
- **æ€§èƒ½ä¼˜åŒ–** - é¿å…ç½‘ç»œè°ƒç”¨ï¼Œæå‡å¤„ç†é€Ÿåº¦

### ğŸ› ï¸ æŠ€æœ¯å®ç°

#### 1. åˆ†è¯å™¨åµŒå…¥åˆ° TEI æœåŠ¡
```
TEI Container
â”œâ”€â”€ é‡æ’åºæ¨¡å‹
â”œâ”€â”€ åµŒå…¥æ¨¡å‹  
â”œâ”€â”€ åˆ†è¯å™¨ç¼“å­˜ âœ…
â”œâ”€â”€ åˆ†è¯å™¨å¤„ç†é€»è¾‘ âœ…
â””â”€â”€ ç»Ÿä¸€ API æ¥å£ âœ…
```

#### 2. å®Œæ•´çš„æ–‡æœ¬å¤„ç†æµç¨‹
```mermaid
graph LR
    A[åŸå§‹æ–‡æœ¬] --> B[åˆ†è¯å™¨å¤„ç†]
    B --> C[Token ç¼–ç ]
    C --> D[æ¨¡å‹æ¨ç†]
    D --> E[é‡æ’åºç»“æœ]
    
    style B fill:#ff9999
    style C fill:#ff9999
    style D fill:#99ccff
    style E fill:#99ff99
```

#### 3. é›†æˆæ¶æ„
```
New API
â”œâ”€â”€ HuggingFace TEI Channel
â”‚   â”œâ”€â”€ è¯·æ±‚å¤„ç†
â”‚   â”œâ”€â”€ åˆ†è¯å™¨è°ƒç”¨ âœ…
â”‚   â”œâ”€â”€ æ¨¡å‹æ¨ç†
â”‚   â””â”€â”€ ç»“æœè¿”å›
â””â”€â”€ åˆ†è¯å™¨ç®¡ç†ç³»ç»Ÿ
    â”œâ”€â”€ é¢„ä¸‹è½½æœºåˆ¶ âœ…
    â”œâ”€â”€ ç¼“å­˜ç®¡ç† âœ…
    â”œâ”€â”€ çŠ¶æ€ç›‘æ§ âœ…
    â””â”€â”€ æ›´æ–°ç»´æŠ¤ âœ…
```

## ğŸ”§ åˆ†è¯å™¨é›†æˆç‰¹æ€§

### 1. è‡ªåŠ¨åˆ†è¯å¤„ç†
```python
# ç”¨æˆ·è¾“å…¥
{
  "query": "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
  "documents": [
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
    "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ"
  ]
}

# å†…éƒ¨è‡ªåŠ¨å¤„ç†
query_tokens = tokenizer.encode("æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ")
doc_tokens = [
  tokenizer.encode("æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯"),
  tokenizer.encode("æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ")
]

# æ¨¡å‹æ¨ç†
scores = model(query_tokens, doc_tokens)
```

### 2. å¤šæ¨¡å‹åˆ†è¯å™¨æ”¯æŒ
æ¯ä¸ªæ¨¡å‹éƒ½æœ‰å¯¹åº”çš„åˆ†è¯å™¨ï¼š

| æ¨¡å‹ | åˆ†è¯å™¨ç±»å‹ | ç‰¹ç‚¹ |
|------|------------|------|
| `BAAI/bge-reranker-v2-m3` | BertTokenizer | å¤šè¯­è¨€æ”¯æŒ |
| `jinaai/jina-reranker-v2` | JinaTokenizer | ä¼˜åŒ–çš„ç¼–ç  |
| `cross-encoder/ms-marco` | AutoTokenizer | é€šç”¨å…¼å®¹ |

### 3. æ™ºèƒ½ç¼“å­˜æœºåˆ¶
```
åˆ†è¯å™¨ç¼“å­˜ç»“æ„
/data/cache/
â”œâ”€â”€ models--BAAI--bge-reranker-v2-m3/
â”‚   â”œâ”€â”€ tokenizer.json âœ…
â”‚   â”œâ”€â”€ tokenizer_config.json âœ…
â”‚   â”œâ”€â”€ vocab.txt âœ…
â”‚   â””â”€â”€ special_tokens_map.json âœ…
â”œâ”€â”€ models--jinaai--jina-reranker-v2/
â”‚   â”œâ”€â”€ tokenizer.json âœ…
â”‚   â””â”€â”€ tokenizer_config.json âœ…
â””â”€â”€ offline_config.json âœ…
```

## âš¡ æ€§èƒ½ä¼˜åŠ¿

### ğŸš€ å¤„ç†é€Ÿåº¦æå‡
- **æ— ç½‘ç»œå»¶è¿Ÿ** - åˆ†è¯å™¨æœ¬åœ°å¤„ç†ï¼Œé¿å…ç½‘ç»œè°ƒç”¨
- **æ‰¹é‡ä¼˜åŒ–** - æ”¯æŒæ‰¹é‡æ–‡æœ¬çš„é«˜æ•ˆåˆ†è¯
- **å†…å­˜å¤ç”¨** - åˆ†è¯å™¨å®ä¾‹å¤ç”¨ï¼Œå‡å°‘åˆå§‹åŒ–å¼€é”€

### ğŸ“Š æ€§èƒ½å¯¹æ¯”
| æŒ‡æ ‡ | å¤–éƒ¨åˆ†è¯å™¨ | é›†æˆåˆ†è¯å™¨ |
|------|------------|------------|
| åˆ†è¯å»¶è¿Ÿ | 50-100ms | **5-10ms** |
| ç½‘ç»œä¾èµ– | âœ… éœ€è¦ | **âŒ æ— éœ€** |
| èµ„æºä½¿ç”¨ | é«˜ | **ä½** |
| å¯é æ€§ | ä¸­ç­‰ | **é«˜** |

## ğŸ”„ å®Œæ•´çš„å¤„ç†æµç¨‹

### 1. è¯·æ±‚æ¥æ”¶
```http
POST /v1/rerank
{
  "model": "BAAI/bge-reranker-v2-m3",
  "query": "äººå·¥æ™ºèƒ½åº”ç”¨",
  "documents": ["æ–‡æ¡£1", "æ–‡æ¡£2", "æ–‡æ¡£3"]
}
```

### 2. åˆ†è¯å™¨è‡ªåŠ¨é€‰æ‹©
```go
// æ ¹æ®æ¨¡å‹è‡ªåŠ¨é€‰æ‹©å¯¹åº”çš„åˆ†è¯å™¨
tokenizer := getTokenizerForModel("BAAI/bge-reranker-v2-m3")
```

### 3. æ–‡æœ¬é¢„å¤„ç†
```python
# æŸ¥è¯¢åˆ†è¯
query_tokens = tokenizer.encode(
    "äººå·¥æ™ºèƒ½åº”ç”¨",
    max_length=512,
    truncation=True,
    padding=True
)

# æ–‡æ¡£åˆ†è¯
doc_tokens = []
for doc in documents:
    tokens = tokenizer.encode(
        doc,
        max_length=512,
        truncation=True,
        padding=True
    )
    doc_tokens.append(tokens)
```

### 4. æ¨¡å‹æ¨ç†
```python
# é‡æ’åºæ¨ç†
with torch.no_grad():
    scores = model(query_tokens, doc_tokens)
```

### 5. ç»“æœè¿”å›
```json
{
  "results": [
    {
      "index": 0,
      "relevance_score": 0.95,
      "document": "æ–‡æ¡£1"
    }
  ]
}
```

## ğŸ› ï¸ ç®¡ç†å’Œç»´æŠ¤

### 1. åˆ†è¯å™¨çŠ¶æ€ç›‘æ§
```bash
# æŸ¥çœ‹åˆ†è¯å™¨çŠ¶æ€
curl http://localhost:3000/api/tokenizer/

# å“åº”ç¤ºä¾‹
{
  "success": true,
  "data": [
    {
      "model_name": "BAAI/bge-reranker-v2-m3",
      "status": "available",
      "tokenizer_type": "BertTokenizer",
      "vocab_size": 30522,
      "cache_size": "45MB"
    }
  ]
}
```

### 2. åˆ†è¯å™¨æ›´æ–°
```bash
# æ›´æ–°ç‰¹å®šæ¨¡å‹çš„åˆ†è¯å™¨
curl -X POST http://localhost:3000/api/tokenizer/update \
  -H "Content-Type: application/json" \
  -d '{
    "channel_id": 1,
    "models": ["BAAI/bge-reranker-v2-m3"],
    "force": false
  }'
```

### 3. ç¼“å­˜ç®¡ç†
```bash
# å®¹å™¨å†…åˆ†è¯å™¨ç®¡ç†
docker exec tei-container python3 /usr/local/bin/tokenizer_manager.py list
docker exec tei-container python3 /usr/local/bin/tokenizer_manager.py verify
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. åˆ†è¯å™¨åŠ è½½å¤±è´¥
**ç—‡çŠ¶**: API è¿”å›åˆ†è¯å™¨é”™è¯¯
```json
{
  "error": "Tokenizer not found for model: xxx"
}
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥åˆ†è¯å™¨ç¼“å­˜
docker exec tei-container ls -la /data/cache/

# é‡æ–°ä¸‹è½½åˆ†è¯å™¨
docker exec tei-container python3 /usr/local/bin/tokenizer_manager.py update --model MODEL_NAME
```

#### 2. åˆ†è¯ç»“æœå¼‚å¸¸
**ç—‡çŠ¶**: é‡æ’åºç»“æœä¸å‡†ç¡®

**è§£å†³æ–¹æ¡ˆ**:
```bash
# éªŒè¯åˆ†è¯å™¨å®Œæ•´æ€§
docker exec tei-container python3 /usr/local/bin/tokenizer_manager.py verify

# æµ‹è¯•åˆ†è¯å™¨
docker exec tei-container python3 -c "
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-m3', cache_dir='/data/cache')
print(tokenizer.encode('æµ‹è¯•æ–‡æœ¬'))
"
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. éƒ¨ç½²å»ºè®®
- **é¢„ç•™å­˜å‚¨** - ä¸ºåˆ†è¯å™¨ç¼“å­˜é¢„ç•™è¶³å¤Ÿç©ºé—´ (50GB+)
- **å†…å­˜é…ç½®** - æ ¹æ®æ¨¡å‹æ•°é‡åˆç†åˆ†é…å†…å­˜
- **å¹¶å‘è®¾ç½®** - è€ƒè™‘åˆ†è¯å™¨å¤„ç†çš„å¹¶å‘éœ€æ±‚

### 2. æ€§èƒ½ä¼˜åŒ–
- **æ‰¹é‡å¤„ç†** - å°½é‡ä½¿ç”¨æ‰¹é‡ API æå‡æ•ˆç‡
- **ç¼“å­˜é¢„çƒ­** - å¯åŠ¨åé¢„åŠ è½½å¸¸ç”¨åˆ†è¯å™¨
- **èµ„æºç›‘æ§** - ç›‘æ§åˆ†è¯å™¨å†…å­˜å’Œ CPU ä½¿ç”¨

### 3. ç»´æŠ¤ç­–ç•¥
- **å®šæœŸéªŒè¯** - å®šæœŸæ£€æŸ¥åˆ†è¯å™¨å®Œæ•´æ€§
- **ç‰ˆæœ¬ç®¡ç†** - è·Ÿè¸ªåˆ†è¯å™¨ç‰ˆæœ¬å˜æ›´
- **å¤‡ä»½æ¢å¤** - å®šæœŸå¤‡ä»½åˆ†è¯å™¨ç¼“å­˜

## ğŸš€ æœªæ¥è§„åˆ’

### çŸ­æœŸæ”¹è¿›
- [ ] æ”¯æŒè‡ªå®šä¹‰åˆ†è¯å™¨é…ç½®
- [ ] å¢åŠ åˆ†è¯å™¨æ€§èƒ½ç›‘æ§
- [ ] ä¼˜åŒ–åˆ†è¯å™¨åŠ è½½é€Ÿåº¦

### é•¿æœŸè§„åˆ’
- [ ] æ”¯æŒåŠ¨æ€åˆ†è¯å™¨åŠ è½½
- [ ] å®ç°åˆ†è¯å™¨çƒ­æ›´æ–°
- [ ] æ·»åŠ åˆ†è¯å™¨ A/B æµ‹è¯•

## ğŸ“Š æ€»ç»“

New API v1.6.0 çš„åˆ†è¯å™¨åŠŸèƒ½å®Œå…¨é›†æˆå¸¦æ¥äº†ï¼š

- âœ… **é›¶å¤–éƒ¨ä¾èµ–** - æ— éœ€é¢å¤–çš„åˆ†è¯å™¨æœåŠ¡
- âœ… **ç«¯åˆ°ç«¯å¤„ç†** - å®Œæ•´çš„æ–‡æœ¬å¤„ç†æµç¨‹
- âœ… **é«˜æ€§èƒ½** - æœ¬åœ°å¤„ç†ï¼Œé¿å…ç½‘ç»œå»¶è¿Ÿ
- âœ… **æ˜“ç®¡ç†** - ç»Ÿä¸€çš„ç®¡ç†å’Œç›‘æ§ç•Œé¢
- âœ… **é«˜å¯é ** - ç¦»çº¿è¿è¡Œï¼Œä¸å—ç½‘ç»œå½±å“

è¿™ä½¿å¾— New API æˆä¸ºä¸€ä¸ªçœŸæ­£è‡ªåŒ…å«çš„é‡æ’åºè§£å†³æ–¹æ¡ˆï¼
